{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Survey of Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical data for lake levels and stream flows in the Rainy Lake watershed are publically available from several sources including the [Water Survey of Canada](http://wateroffice.ec.gc.ca/).\n",
    "\n",
    "For the calculations in these notebooks, the [HYDAT database](https://www.ec.gc.ca/rhc-wsc/default.asp?lang=En&n=9018B5EC-1) containing historical data from the water survey of Canada was downloaded from Environment Canada. The database consists of a Microsoft Access .mdb file. Individual tables (STATIONS, DLY_FLOWS, and DLY_LEVELS) from the database were extracted to .csv files using [MDB Explorer](http://www.mdbexplorer.com/) and stored in the data directory.\n",
    "\n",
    "This notebook extracts python dataframes from the .csv files, then creates two dataframes, RL and NL, for daily levels on Rainy and Namakan lakes, and RR for flows on Rainy River."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display graphics inline with the notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "# Standard Python modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Module to enhance matplotlib plotting\n",
    "#import seaborn\n",
    "#seaborn.set()\n",
    "\n",
    "# Modules to display images and data tables\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data Tables\n",
    "\n",
    "Before proceeding, download the HYDAT.mdb downloaded from Environment Canada, extract tables `STATIONS`, `DLY_FLOWS` and `DLY_LEVELS` and store as CSV formatted file. The name of the directory is encoded as `HYDAT_dir`.\n",
    "\n",
    "The following cell checks the repository data directory for the existance of an HDF5 formatted file `hydat.h5` which is intended to be a small cache of the HYDAT data relevant to the Rainy/Namakan Lake system. If so, the data is read from `hydat.h5`. Otherwise, if the file does not exist, the entire HYDAT data based is read from CSV formatted files located in the directory `HYDAT_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.pytables.HDFStore'>\n",
      "File path: data/hydat.h5\n",
      "/DLY_FLOWS             frame        (shape->[3479,73])\n",
      "/DLY_LEVELS            frame        (shape->[4196,74])\n",
      "/STATIONS              frame        (shape->[13,14])  \n",
      "STATIONS.size =  182\n",
      "DLY_LEVELS.size =  310504\n",
      "DLY_FLOWS.size =  253967\n"
     ]
    }
   ],
   "source": [
    "from os.path import isfile\n",
    "\n",
    "# Directory where data files have been stored\n",
    "HYDAT_dir = \"/Users/jeff/Box Sync/RLPOA Technical Committee/Historical Data/HYDAT/\"\n",
    "\n",
    "# check if a hydat.h5 file is the repository data directory. Read from there, otherwise\n",
    "# read HYDAT CSV tables.\n",
    "if isfile('data/hydat.h5'):\n",
    "    hydat = pd.HDFStore('data/hydat.h5')\n",
    "    STATIONS = hydat['STATIONS']\n",
    "    DLY_FLOWS = hydat['DLY_FLOWS']\n",
    "    DLY_LEVELS = hydat['DLY_LEVELS']\n",
    "    print hydat\n",
    "else:\n",
    "    # The following csv data tables were extracted from the HYDAT .mdb dataset\n",
    "    STATIONS = pd.read_csv(HYDAT_dir + 'STATIONS.csv', index_col = 0);\n",
    "    DLY_FLOWS = pd.read_csv(HYDAT_dir + 'DLY_FLOWS.csv');\n",
    "    DLY_LEVELS = pd.read_csv(HYDAT_dir + 'DLY_LEVELS.csv');\n",
    "\n",
    "print \"STATIONS.size = \", STATIONS.size\n",
    "print \"DLY_LEVELS.size = \", DLY_LEVELS.size\n",
    "print \"DLY_FLOWS.size = \", DLY_FLOWS.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping WSC Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HYDAT database is a collection of data associated with monitoring stations located throughout Canada. The STATIONS table contains a list of stations and attributes, including the latitude and longitude of their position. As an example, here we list attributes for 05PB007, a station monitoring the level of Rainy Lake near Fort Frances, Ontario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION_NAME            RAINY LAKE NEAR FORT FRANCES\n",
       "PROV_TERR_STATE_LOC                               ON\n",
       "REGIONAL_OFFICE_ID                                 5\n",
       "HYD_STATUS                                         A\n",
       "SED_STATUS                                       NaN\n",
       "LATITUDE                                     48.6491\n",
       "LONGITUDE                                   -93.3207\n",
       "DRAINAGE_AREA_GROSS                              NaN\n",
       "DRAINAGE_AREA_EFFECT                             NaN\n",
       "RHBN                                               0\n",
       "REAL_TIME                                          1\n",
       "CONTRIBUTOR_ID                                   647\n",
       "OPERATOR_ID                                      647\n",
       "DATUM_ID                                         100\n",
       "Name: 05PB007, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATIONS.ix['05PB007']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function maps a list of stations identified by their station numbers. In extracts latitude and longitude from the STATIONS table, then calls the google maps web api to create a map image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapWSC(stationList):\n",
    "    S = STATIONS.ix[stationList,['STATION_NAME','LATITUDE','LONGITUDE']]\n",
    "    locs = [\"{0},{1}\".format(S.ix[s,'LATITUDE'], S.ix[s,'LONGITUDE']) \\\n",
    "             for s in S.index]\n",
    "    google_maps_url = \\\n",
    "        \"https://maps.googleapis.com/maps/api/staticmap?\" + \\\n",
    "        \"size=640x320\" + \\\n",
    "        \"&maptype=terrain\" + \\\n",
    "        \"&markers=color:red%7Csize:mid%7C\" + \"|\".join(locs)\n",
    "    img = Image(url = google_maps_url)    \n",
    "    display(img)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level Monitoring Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://maps.googleapis.com/maps/api/staticmap?size=640x320&maptype=terrain&markers=color:red%7Csize:mid%7C48.64912,-93.32068|48.70058,-92.958|48.75197,-91.58408|48.38256,-92.17631|48.49686,-92.65856|48.84167,-93.62|48.61389,-93.35472|48.61625,-93.35992|48.35508,-92.21744|48.5,-92.63886\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05PB007</th>\n",
       "      <td>RAINY LAKE NEAR FORT FRANCES</td>\n",
       "      <td>48.64912</td>\n",
       "      <td>-93.32068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PB024</th>\n",
       "      <td>RAINY LAKE NEAR BEAR PASS</td>\n",
       "      <td>48.70058</td>\n",
       "      <td>-92.95800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PB018</th>\n",
       "      <td>ATIKOKAN RIVER AT ATIKOKAN</td>\n",
       "      <td>48.75197</td>\n",
       "      <td>-91.58408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PA006</th>\n",
       "      <td>NAMAKAN RIVER AT OUTLET OF LAC LA CROIX</td>\n",
       "      <td>48.38256</td>\n",
       "      <td>-92.17631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PA013</th>\n",
       "      <td>NAMAKAN LAKE AT SQUIRREL ISLAND</td>\n",
       "      <td>48.49686</td>\n",
       "      <td>-92.65856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PB023</th>\n",
       "      <td>RAINY LAKE AT NORTHWEST BAY</td>\n",
       "      <td>48.84167</td>\n",
       "      <td>-93.62000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PC024</th>\n",
       "      <td>RAINY RIVER AT PITHERS POINT SITE NO.1</td>\n",
       "      <td>48.61389</td>\n",
       "      <td>-93.35472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PC025</th>\n",
       "      <td>RAINY RIVER AT PITHERS POINT SITE NO.2</td>\n",
       "      <td>48.61625</td>\n",
       "      <td>-93.35992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PA011</th>\n",
       "      <td>LAC LA CROIX AT CAMPBELL'S CAMP</td>\n",
       "      <td>48.35508</td>\n",
       "      <td>-92.21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PA003</th>\n",
       "      <td>NAMAKAN LAKE ABOVE KETTLE FALLS DAM</td>\n",
       "      <td>48.50000</td>\n",
       "      <td>-92.63886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           STATION_NAME  LATITUDE  LONGITUDE\n",
       "STATION_NUMBER                                                              \n",
       "05PB007                    RAINY LAKE NEAR FORT FRANCES  48.64912  -93.32068\n",
       "05PB024                       RAINY LAKE NEAR BEAR PASS  48.70058  -92.95800\n",
       "05PB018                      ATIKOKAN RIVER AT ATIKOKAN  48.75197  -91.58408\n",
       "05PA006         NAMAKAN RIVER AT OUTLET OF LAC LA CROIX  48.38256  -92.17631\n",
       "05PA013                 NAMAKAN LAKE AT SQUIRREL ISLAND  48.49686  -92.65856\n",
       "05PB023                     RAINY LAKE AT NORTHWEST BAY  48.84167  -93.62000\n",
       "05PC024          RAINY RIVER AT PITHERS POINT SITE NO.1  48.61389  -93.35472\n",
       "05PC025          RAINY RIVER AT PITHERS POINT SITE NO.2  48.61625  -93.35992\n",
       "05PA011                 LAC LA CROIX AT CAMPBELL'S CAMP  48.35508  -92.21744\n",
       "05PA003             NAMAKAN LAKE ABOVE KETTLE FALLS DAM  48.50000  -92.63886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levelStations = ['05PB007','05PB024','05PB018','05PA006','05PA013', \\\n",
    "               '05PB023','05PC024','05PC025','05PA011','05PA003']\n",
    "\n",
    "mapWSC(levelStations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Monitoring Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://maps.googleapis.com/maps/api/staticmap?size=640x320&maptype=terrain&markers=color:red%7Csize:mid%7C48.63447,-93.91336|48.60853,-93.40344|48.85022,-92.72383\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05PC018</th>\n",
       "      <td>RAINY RIVER AT MANITOU RAPIDS</td>\n",
       "      <td>48.63447</td>\n",
       "      <td>-93.91336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PC019</th>\n",
       "      <td>RAINY RIVER AT FORT FRANCES</td>\n",
       "      <td>48.60853</td>\n",
       "      <td>-93.40344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05PB014</th>\n",
       "      <td>TURTLE RIVER NEAR MINE CENTRE</td>\n",
       "      <td>48.85022</td>\n",
       "      <td>-92.72383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 STATION_NAME  LATITUDE  LONGITUDE\n",
       "STATION_NUMBER                                                    \n",
       "05PC018         RAINY RIVER AT MANITOU RAPIDS  48.63447  -93.91336\n",
       "05PC019           RAINY RIVER AT FORT FRANCES  48.60853  -93.40344\n",
       "05PB014         TURTLE RIVER NEAR MINE CENTRE  48.85022  -92.72383"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowStations = ['05PC018','05PC019','05PB014']\n",
    "mapWSC(flowStations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `hydat.h5` Data Cache\n",
    "\n",
    "Reading the entire HYDAT database is a lengthy operation, and because of file size constraints, the entire data set can not be stored in a github repository or hosted on a docker server. For those reaaons, the an HDF5 data cache is created in the local repository to include selected data relevant to the Rainy/Namakan system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ../data/hydat.h5\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "``../data`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-eb3b4916c6a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/hydat.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Creating ../data/hydat.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhydat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/hydat.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# store data in hydat.h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'can not be written'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/tables/file.pyc\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0mopenFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/tables/file.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new (tables/hdf5extension.c:4195)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/tables/utils.pyc\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeff/anaconda/lib/python2.7/site-packages/tables/utils.pyc\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mparentname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"``%s`` does not exist\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"``%s`` is not a directory\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: ``../data`` does not exist"
     ]
    }
   ],
   "source": [
    "if not isfile('../data/hydat.h5'):\n",
    "    print 'Creating ../data/hydat.h5'\n",
    "    hydat = pd.HDFStore('/data/hydat.h5')\n",
    "    \n",
    "    # store data in hydat.h5\n",
    "    hydat['STATIONS'] = STATIONS.ix[levelStations + flowStations]\n",
    "    hydat['DLY_FLOWS'] = DLY_FLOWS[DLY_FLOWS['STATION_NUMBER'].isin(flowStations)]\n",
    "    hydat['DLY_LEVELS'] = DLY_LEVELS[DLY_LEVELS['STATION_NUMBER'].isin(levelStations)]\n",
    "    \n",
    "    # reload from cache (to verify data round trip)\n",
    "    STATIONS = hydat['STATIONS']\n",
    "    DLY_LEVELS = hydat['DLY_LEVELS']\n",
    "    DLY_FLOWS = hydat['DLY_FLOWS']\n",
    "    \n",
    "hydat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Daily Level Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines a utility function to create a Pandas Series containing the history of levels for a given WSC sensor. The returned object indexed with a daily timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLevelsWSC(s):\n",
    "    global DLY_LEVELS\n",
    "    data = DLY_LEVELS[DLY_LEVELS['STATION_NUMBER'] == s]\n",
    "    ts = {}\n",
    "    for k in data.index:\n",
    "        mo = str(data.ix[k,'MONTH'])\n",
    "        yr = str(data.ix[k,'YEAR'])\n",
    "        for n in range(1,data.ix[k,'NO_DAYS']+1):\n",
    "            ts[pd.to_datetime(mo+'/'+str(n)+'/'+yr)] = data.ix[k,'LEVEL'+str(n)]  \n",
    "    ts = pd.Series(ts)\n",
    "    ts.name = STATIONS.ix[s,'STATION_NAME'] + ' (' + s + ')'\n",
    "    # drop initial and terminal null entries\n",
    "    j = 0\n",
    "    while pd.isnull(ts.ix[j]):\n",
    "        j += 1\n",
    "    k = len(ts.index) - 1\n",
    "    while pd.isnull(ts.ix[k]):\n",
    "        k += -1\n",
    "    return ts[j:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Comparing Levels on Rainy and Namakan Lakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of this function is demonstrated by reading and plotting the history of lake levels for Rainy and Namakan Lakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RL = getLevelsWSC('05PB007')\n",
    "NL = getLevelsWSC('05PA003')\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.hold(True)\n",
    "RL.plot()\n",
    "NL.plot()\n",
    "plt.hold(False)\n",
    "plt.legend([RL.name,NL.name]);\n",
    "plt.title('History of Rainy Lake and Namakan Lake Levels, 1911-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print RL.head()\n",
    "print RL.tail()\n",
    "print NL.head()\n",
    "print NL.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Daily Flow Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines a utility function to create a Pandas Series containing the history of flow data for a given WSC sensor. The returned object indexed with a daily timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFlowsWSC(s):\n",
    "    data = DLY_FLOWS[DLY_FLOWS['STATION_NUMBER'] == s]\n",
    "    ts = {}\n",
    "    for k in data.index:\n",
    "        mo = str(data.ix[k,'MONTH'])\n",
    "        yr = str(data.ix[k,'YEAR'])\n",
    "        for n in range(1,data.ix[k,'NO_DAYS']+1):\n",
    "            ts[pd.to_datetime(mo+'/'+str(n)+'/'+yr)] = data.ix[k,'FLOW'+str(n)]  \n",
    "    ts = pd.Series(ts)\n",
    "    ts.name = STATIONS.ix[s,'STATION_NAME'] + ' (' + s + ')'\n",
    "    # drop initial and terminal null entries\n",
    "    j = 0\n",
    "    while pd.isnull(ts.ix[j]):\n",
    "        j += 1\n",
    "    k = len(ts.index) - 1\n",
    "    while pd.isnull(ts.ix[k]):\n",
    "        k += -1 \n",
    "    return ts[j:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Distribution of Flows on Rainy River"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of this function is demonstrated by creating a historgram of flows on Rainy River in the period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RR = getFlowsWSC('05PC019')\n",
    "plt.subplot(2,1,1)\n",
    "RR.plot()\n",
    "plt.title(RR.name)\n",
    "plt.subplot(2,1,2)\n",
    "RR.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print RR.head()\n",
    "print RR.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
